{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class Dropout:\n",
    "    def __init__(self, rate):\n",
    "        self.rate = rate\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.mask = np.random.binomial(1, 1 - self.rate, size=inputs.shape) / (1 - self.rate)\n",
    "        return inputs * self.mask\n",
    "\n",
    "    def backward(self, grad):\n",
    "        return grad * self.mask\n",
    "\n",
    "\n",
    "class Fungal:\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, input_size ** -0.5, (input_size, hidden_size))\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, hidden_size ** -0.5, (hidden_size, output_size))\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.learning_rate = 0.1\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.hidden_inputs = np.dot(inputs, self.weights_input_to_hidden)\n",
    "        self.hidden_outputs = self.sigmoid(self.hidden_inputs)\n",
    "        self.dropped_outputs = self.dropout.forward(self.hidden_outputs)\n",
    "        self.final_inputs = np.dot(self.dropped_outputs, self.weights_hidden_to_output)\n",
    "        self.final_outputs = self.final_inputs\n",
    "        return self.final_outputs\n",
    "\n",
    "    # ... rest of the class would be the same\n",
    "\n",
    "\n",
    "class FungalEnsemble:\n",
    "    def __init__(self, n_models, input_size, hidden_size, output_size, dropout_rate):\n",
    "        self.models = [Fungal(input_size, hidden_size, output_size, dropout_rate) for _ in range(n_models)]\n",
    "\n",
    "    def train(self, features, targets):\n",
    "        for model in self.models:\n",
    "            X_train, _, y_train, _ = train_test_split(features, targets, test_size=0.5)\n",
    "            model.train(X_train, y_train)\n",
    "\n",
    "    def predict(self, features):\n",
    "        predictions = np.mean([model.predict(features) for model in self.models], axis=0)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Hypothetical data\n",
    "X_train = np.random.rand(1000, 10)  # 1000 samples, 10 features each\n",
    "y_train = np.random.randint(2, size=1000)  # 1000 binary labels\n",
    "X_test = np.random.rand(200, 10)  # 200 samples, 10 features each\n",
    "\n",
    "# Network architecture parameters\n",
    "n_models = 3\n",
    "input_size = 10  # Number of features\n",
    "hidden_size = 20  # Size of the hidden layer\n",
    "output_size = 1  # Binary output\n",
    "dropout_rate = 0.5  # Dropout rate\n",
    "\n",
    "# Create and train the Fungal Ensemble\n",
    "ensemble = FungalEnsemble(n_models, input_size, hidden_size, output_size, dropout_rate)\n",
    "ensemble.train(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = ensemble.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Fungal(tf.keras.Model):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        super(Fungal, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(hidden_size, activation='sigmoid')\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dense2 = tf.keras.layers.Dense(output_size)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.dense1(inputs)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        return self.dense2(x)\n",
    "\n",
    "class FungalEnsemble():\n",
    "    def __init__(self, n_models, input_size, hidden_size, output_size, dropout_rate):\n",
    "        self.models = [Fungal(input_size, hidden_size, output_size, dropout_rate) for _ in range(n_models)]\n",
    "\n",
    "    def train(self, features, targets):\n",
    "        for model in self.models:\n",
    "            X_train, _, y_train, _ = train_test_split(features, targets, test_size=0.5)\n",
    "            model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "    def predict(self, features):\n",
    "        predictions = np.mean([model.predict(features) for model in self.models], axis=0)\n",
    "        return predictions\n",
    "\n",
    "# Hypothetical data\n",
    "X_train = np.random.rand(1000, 10)  # 1000 samples, 10 features each\n",
    "y_train = np.random.randint(2, size=1000)  # 1000 binary labels\n",
    "X_test = np.random.rand(200, 10)  # 200 samples, 10 features each\n",
    "\n",
    "# Network architecture parameters\n",
    "n_models = 3\n",
    "input_size = 10  # Number of features\n",
    "hidden_size = 20  # Size of the hidden layer\n",
    "output_size = 1  # Binary output\n",
    "dropout_rate = 0.5  # Dropout rate\n",
    "\n",
    "# Create and train the Fungal Ensemble\n",
    "ensemble = FungalEnsemble(n_models, input_size, hidden_size, output_size, dropout_rate)\n",
    "ensemble.train(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = ensemble.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AdaptableLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(AdaptableLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "class Fungal(tf.keras.Model):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        super(Fungal, self).__init__()\n",
    "        self.dense1 = AdaptableLayer(hidden_size)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dense2 = tf.keras.layers.Dense(output_size)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.dense1(inputs)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        return self.dense2(x)\n",
    "\n",
    "# Hypothetical data\n",
    "X_train = np.random.rand(1000, 10)  # 1000 samples, 10 features each\n",
    "y_train = np.random.randint(2, size=1000)  # 1000 binary labels\n",
    "X_test = np.random.rand(200, 10)  # 200 samples, 10 features each\n",
    "\n",
    "# Network architecture parameters\n",
    "input_size = 10  # Number of features\n",
    "hidden_size = 20  # Size of the hidden layer\n",
    "output_size = 1  # Binary output\n",
    "dropout_rate = 0.5  # Dropout rate\n",
    "\n",
    "# Create and train the Fungal model\n",
    "fungal = Fungal(input_size, hidden_size, output_size, dropout_rate)\n",
    "\n",
    "# Compile and train the model\n",
    "fungal.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "fungal.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Make predictions\n",
    "predictions = fungal.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import neat\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load configuration.\n",
    "config = neat.Config(\n",
    "    neat.DefaultGenome,\n",
    "    neat.DefaultReproduction,\n",
    "    neat.DefaultSpeciesSet,\n",
    "    neat.DefaultStagnation,\n",
    "    'config_file'  # This should be the path to your configuration file\n",
    ")\n",
    "\n",
    "# 2. Create the population, which is the top-level object for a NEAT run.\n",
    "p = neat.Population(config)\n",
    "\n",
    "# 3. Define a fitness function.\n",
    "def eval_genomes(genomes, config):\n",
    "    for genome_id, genome in genomes:\n",
    "        genome.fitness = 4.0\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        for xi, xo in zip(X_train, y_train):\n",
    "            output = net.activate(xi)\n",
    "            genome.fitness -= (output[0] - xo) ** 2\n",
    "\n",
    "# 4. Run the NEAT algorithm for up to 300 generations.\n",
    "winner = p.run(eval_genomes, 300)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import neat\n",
    "import numpy as np\n",
    "\n",
    "# Load configuration\n",
    "config = neat.Config(\n",
    "    neat.DefaultGenome,\n",
    "    neat.DefaultReproduction,\n",
    "    neat.DefaultSpeciesSet,\n",
    "    neat.DefaultStagnation,\n",
    "    'config_file'  # Replace with your config file path\n",
    ")\n",
    "\n",
    "# Create the population\n",
    "p = neat.Population(config)\n",
    "\n",
    "# Define a dynamic environment\n",
    "class DynamicEnvironment:\n",
    "    def __init__(self):\n",
    "        self.change_frequency = 100  # Change environment every 100 generations\n",
    "        self.current_state = self.generate_state()\n",
    "\n",
    "    def generate_state(self):\n",
    "        # Replace with your own logic\n",
    "        return np.random.rand()\n",
    "\n",
    "    def get_state(self, generation):\n",
    "        if generation % self.change_frequency == 0:\n",
    "            self.current_state = self.generate_state()\n",
    "        return self.current_state\n",
    "\n",
    "env = DynamicEnvironment()\n",
    "\n",
    "# Define a fitness function that takes the environment into account\n",
    "def eval_genomes(genomes, config):\n",
    "    for genome_id, genome in genomes:\n",
    "        genome.fitness = 4.0\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        for xi, xo in zip(X_train, y_train):\n",
    "            output = net.activate(xi)\n",
    "            # Fitness depends on the current state of the environment\n",
    "            state = env.get_state(genome_id)\n",
    "            genome.fitness -= (output[0] - xo - state) ** 2\n",
    "\n",
    "# Run the NEAT algorithm for up to 300 generations\n",
    "winner = p.run(eval_genomes, 300)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
