{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class Dropout:\n",
    "    def __init__(self, rate):\n",
    "        self.rate = rate\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.mask = np.random.binomial(1, 1 - self.rate, size=inputs.shape) / (1 - self.rate)\n",
    "        return inputs * self.mask\n",
    "\n",
    "    def backward(self, grad):\n",
    "        return grad * self.mask\n",
    "\n",
    "\n",
    "class Fungal:\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, input_size ** -0.5, (input_size, hidden_size))\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, hidden_size ** -0.5, (hidden_size, output_size))\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.learning_rate = 0.1\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.hidden_inputs = np.dot(inputs, self.weights_input_to_hidden)\n",
    "        self.hidden_outputs = self.sigmoid(self.hidden_inputs)\n",
    "        self.dropped_outputs = self.dropout.forward(self.hidden_outputs)\n",
    "        self.final_inputs = np.dot(self.dropped_outputs, self.weights_hidden_to_output)\n",
    "        self.final_outputs = self.final_inputs\n",
    "        return self.final_outputs\n",
    "\n",
    "    # ... rest of the class would be the same\n",
    "\n",
    "\n",
    "class FungalEnsemble:\n",
    "    def __init__(self, n_models, input_size, hidden_size, output_size, dropout_rate):\n",
    "        self.models = [Fungal(input_size, hidden_size, output_size, dropout_rate) for _ in range(n_models)]\n",
    "\n",
    "    def train(self, features, targets):\n",
    "        for model in self.models:\n",
    "            X_train, _, y_train, _ = train_test_split(features, targets, test_size=0.5)\n",
    "            model.train(X_train, y_train)\n",
    "\n",
    "    def predict(self, features):\n",
    "        predictions = np.mean([model.predict(features) for model in self.models], axis=0)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Hypothetical data\n",
    "X_train = np.random.rand(1000, 10)  # 1000 samples, 10 features each\n",
    "y_train = np.random.randint(2, size=1000)  # 1000 binary labels\n",
    "X_test = np.random.rand(200, 10)  # 200 samples, 10 features each\n",
    "\n",
    "# Network architecture parameters\n",
    "n_models = 3\n",
    "input_size = 10  # Number of features\n",
    "hidden_size = 20  # Size of the hidden layer\n",
    "output_size = 1  # Binary output\n",
    "dropout_rate = 0.5  # Dropout rate\n",
    "\n",
    "# Create and train the Fungal Ensemble\n",
    "ensemble = FungalEnsemble(n_models, input_size, hidden_size, output_size, dropout_rate)\n",
    "ensemble.train(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = ensemble.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Fungal(tf.keras.Model):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        super(Fungal, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(hidden_size, activation='sigmoid')\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dense2 = tf.keras.layers.Dense(output_size)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.dense1(inputs)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        return self.dense2(x)\n",
    "\n",
    "class FungalEnsemble():\n",
    "    def __init__(self, n_models, input_size, hidden_size, output_size, dropout_rate):\n",
    "        self.models = [Fungal(input_size, hidden_size, output_size, dropout_rate) for _ in range(n_models)]\n",
    "\n",
    "    def train(self, features, targets):\n",
    "        for model in self.models:\n",
    "            X_train, _, y_train, _ = train_test_split(features, targets, test_size=0.5)\n",
    "            model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "    def predict(self, features):\n",
    "        predictions = np.mean([model.predict(features) for model in self.models], axis=0)\n",
    "        return predictions\n",
    "\n",
    "# Hypothetical data\n",
    "X_train = np.random.rand(1000, 10)  # 1000 samples, 10 features each\n",
    "y_train = np.random.randint(2, size=1000)  # 1000 binary labels\n",
    "X_test = np.random.rand(200, 10)  # 200 samples, 10 features each\n",
    "\n",
    "# Network architecture parameters\n",
    "n_models = 3\n",
    "input_size = 10  # Number of features\n",
    "hidden_size = 20  # Size of the hidden layer\n",
    "output_size = 1  # Binary output\n",
    "dropout_rate = 0.5  # Dropout rate\n",
    "\n",
    "# Create and train the Fungal Ensemble\n",
    "ensemble = FungalEnsemble(n_models, input_size, hidden_size, output_size, dropout_rate)\n",
    "ensemble.train(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = ensemble.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AdaptableLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(AdaptableLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "class Fungal(tf.keras.Model):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        super(Fungal, self).__init__()\n",
    "        self.dense1 = AdaptableLayer(hidden_size)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dense2 = tf.keras.layers.Dense(output_size)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.dense1(inputs)\n",
    "        if training:\n",
    "            x = self.dropout(x)\n",
    "        return self.dense2(x)\n",
    "\n",
    "# Hypothetical data\n",
    "X_train = np.random.rand(1000, 10)  # 1000 samples, 10 features each\n",
    "y_train = np.random.randint(2, size=1000)  # 1000 binary labels\n",
    "X_test = np.random.rand(200, 10)  # 200 samples, 10 features each\n",
    "\n",
    "# Network architecture parameters\n",
    "input_size = 10  # Number of features\n",
    "hidden_size = 20  # Size of the hidden layer\n",
    "output_size = 1  # Binary output\n",
    "dropout_rate = 0.5  # Dropout rate\n",
    "\n",
    "# Create and train the Fungal model\n",
    "fungal = Fungal(input_size, hidden_size, output_size, dropout_rate)\n",
    "\n",
    "# Compile and train the model\n",
    "fungal.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "fungal.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Make predictions\n",
    "predictions = fungal.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import neat\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load configuration.\n",
    "config = neat.Config(\n",
    "    neat.DefaultGenome,\n",
    "    neat.DefaultReproduction,\n",
    "    neat.DefaultSpeciesSet,\n",
    "    neat.DefaultStagnation,\n",
    "    'config_file'  # This should be the path to your configuration file\n",
    ")\n",
    "\n",
    "# 2. Create the population, which is the top-level object for a NEAT run.\n",
    "p = neat.Population(config)\n",
    "\n",
    "# 3. Define a fitness function.\n",
    "def eval_genomes(genomes, config):\n",
    "    for genome_id, genome in genomes:\n",
    "        genome.fitness = 4.0\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        for xi, xo in zip(X_train, y_train):\n",
    "            output = net.activate(xi)\n",
    "            genome.fitness -= (output[0] - xo) ** 2\n",
    "\n",
    "# 4. Run the NEAT algorithm for up to 300 generations.\n",
    "winner = p.run(eval_genomes, 300)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import neat\n",
    "import numpy as np\n",
    "\n",
    "# Load configuration\n",
    "config = neat.Config(\n",
    "    neat.DefaultGenome,\n",
    "    neat.DefaultReproduction,\n",
    "    neat.DefaultSpeciesSet,\n",
    "    neat.DefaultStagnation,\n",
    "    'config_file'  # Replace with your config file path\n",
    ")\n",
    "\n",
    "# Create the population\n",
    "p = neat.Population(config)\n",
    "\n",
    "# Define a dynamic environment\n",
    "class DynamicEnvironment:\n",
    "    def __init__(self):\n",
    "        self.change_frequency = 100  # Change environment every 100 generations\n",
    "        self.current_state = self.generate_state()\n",
    "\n",
    "    def generate_state(self):\n",
    "        # Replace with your own logic\n",
    "        return np.random.rand()\n",
    "\n",
    "    def get_state(self, generation):\n",
    "        if generation % self.change_frequency == 0:\n",
    "            self.current_state = self.generate_state()\n",
    "        return self.current_state\n",
    "\n",
    "env = DynamicEnvironment()\n",
    "\n",
    "# Define a fitness function that takes the environment into account\n",
    "def eval_genomes(genomes, config):\n",
    "    for genome_id, genome in genomes:\n",
    "        genome.fitness = 4.0\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        for xi, xo in zip(X_train, y_train):\n",
    "            output = net.activate(xi)\n",
    "            # Fitness depends on the current state of the environment\n",
    "            state = env.get_state(genome_id)\n",
    "            genome.fitness -= (output[0] - xo - state) ** 2\n",
    "\n",
    "# Run the NEAT algorithm for up to 300 generations\n",
    "winner = p.run(eval_genomes, 300)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import neat\n",
    "import numpy as np\n",
    "\n",
    "# Define a dynamic environment\n",
    "class DynamicEnvironment:\n",
    "    def __init__(self):\n",
    "        self.change_frequency = 100  # Change environment every 100 generations\n",
    "        self.current_state = self.generate_state()\n",
    "\n",
    "    def generate_state(self):\n",
    "        # Replace with your own logic\n",
    "        return np.random.rand()\n",
    "\n",
    "    def get_state(self, generation):\n",
    "        if generation % self.change_frequency == 0:\n",
    "            self.current_state = self.generate_state()\n",
    "        return self.current_state\n",
    "\n",
    "env = DynamicEnvironment()\n",
    "\n",
    "# Define a fitness function that takes the environment into account\n",
    "def eval_genomes(genomes, config):\n",
    "    for genome_id, genome in genomes:\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        fitness = 0.0\n",
    "        for xi, xo in zip(X_train, y_train):\n",
    "            output = net.activate(xi)\n",
    "            # Fitness depends on the current state of the environment\n",
    "            state = env.get_state(genome_id)\n",
    "            fitness -= (output[0] - xo - state) ** 2\n",
    "        genome.fitness = fitness\n",
    "\n",
    "# Load configuration\n",
    "config_path = 'config_file'  # Replace with your config file path\n",
    "config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation, config_path)\n",
    "\n",
    "# Create the population\n",
    "population = neat.Population(config)\n",
    "\n",
    "# Add reporters to show progress in the console\n",
    "population.add_reporter(neat.StdOutReporter(True))\n",
    "stats = neat.StatisticsReporter()\n",
    "population.add_reporter(stats)\n",
    "\n",
    "# Run NEAT for a specified number of generations\n",
    "generations = 300\n",
    "winner = population.run(eval_genomes, generations)\n",
    "\n",
    "# Display the winning genome\n",
    "print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "\n",
    "# Use the winning genome to create a network\n",
    "net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "\n",
    "# Test the network on test data\n",
    "predictions = []\n",
    "for xi in X_test:\n",
    "    output = net.activate(xi)\n",
    "    predictions.append(output)\n",
    "\n",
    "# Print predictions\n",
    "print(predictions)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class FungalUnit(tf.keras.Model):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FungalUnit, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(hidden_size, activation='sigmoid')\n",
    "        self.dense2 = tf.keras.layers.Dense(output_size, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return self.dense2(x)\n",
    "\n",
    "class Fungal:\n",
    "    def __init__(self, input_size, hidden_size, output_size, initial_units):\n",
    "        self.units = [FungalUnit(input_size, hidden_size, output_size) for _ in range(initial_units)]\n",
    "        self.learning_rate = 0.1\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = []\n",
    "        for unit in self.units:\n",
    "            output = unit(inputs)\n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "\n",
    "    def adapt(self, inputs, outputs, targets):\n",
    "        # Calculate fitness for each unit\n",
    "        fitness = [self.calculate_fitness(output, target) for output, target in zip(outputs, targets)]\n",
    "\n",
    "        # Perform adaptation based on fitness\n",
    "        for i in range(len(self.units)):\n",
    "            if fitness[i] < threshold:\n",
    "                # Perform growth by creating a new unit\n",
    "                new_unit = FungalUnit(input_size, hidden_size, output_size)\n",
    "                self.units.append(new_unit)\n",
    "            else:\n",
    "                # Perform pruning by removing the unit\n",
    "                del self.units[i]\n",
    "\n",
    "    def calculate_fitness(self, output, target):\n",
    "        # Calculate fitness based on output and target\n",
    "        return 1.0 / (1.0 + np.abs(output - target))\n",
    "\n",
    "    def train(self, X, y, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            outputs = self.forward(X)\n",
    "            self.adapt(X, outputs, y)\n",
    "            self.update_weights(X, y)\n",
    "\n",
    "    def update_weights(self, X, y):\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "        for unit in self.units:\n",
    "            with tf.GradientTape() as tape:\n",
    "                outputs = unit(X)\n",
    "                loss_value = tf.losses.binary_crossentropy(y, outputs)\n",
    "            gradients = tape.gradient(loss_value, unit.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, unit.trainable_variables))\n",
    "\n",
    "    def predict(self, X):\n",
    "        outputs = self.forward(X)\n",
    "        return np.mean(outputs, axis=0)\n",
    "\n",
    "# Hypothetical data\n",
    "X_train = np.random.rand(1000, 10)  # 1000 samples, 10 features each\n",
    "y_train = np.random.randint(2, size=1000)  # 1000 binary labels\n",
    "X_test = np.random.rand(200, 10)  # 200 samples, 10 features each\n",
    "\n",
    "# Network architecture parameters\n",
    "input_size = 10  # Number of features\n",
    "hidden_size = 20  # Size of the hidden layer\n",
    "output_size = 1  # Binary output\n",
    "initial_units = 5  # Initial number of units in the Fungal algorithm\n",
    "threshold = 0.5  # Threshold for adaptation\n",
    "\n",
    "# Create and train the Fungal model\n",
    "fungal = Fungal(input_size, hidden_size, output_size, initial_units)\n",
    "fungal.train(X_train, y_train, num_epochs=10)\n",
    "\n",
    "# Make predictions\n",
    "predictions = fungal.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class FungalUnit(tf.keras.Model):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FungalUnit, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(hidden_size, activation='sigmoid')\n",
    "        self.dense2 = tf.keras.layers.Dense(output_size, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return self.dense2(x)\n",
    "\n",
    "class Fungal:\n",
    "    def __init__(self, input_size, hidden_size, output_size, population_size):\n",
    "        self.population = [FungalUnit(input_size, hidden_size, output_size) for _ in range(population_size)]\n",
    "        self.learning_rate = 0.1\n",
    "\n",
    "    def evaluate_fitness(self, X, y):\n",
    "        fitness_scores = []\n",
    "        for unit in self.population:\n",
    "            outputs = unit(X)\n",
    "            loss = tf.losses.binary_crossentropy(y, outputs)\n",
    "            fitness = 1 / (1 + loss)\n",
    "            fitness_scores.append(fitness)\n",
    "        return fitness_scores\n",
    "\n",
    "    def selection(self, fitness_scores, num_parents):\n",
    "        parents = []\n",
    "        indices = np.argsort(fitness_scores)[::-1]  # Sort indices in descending order\n",
    "        for i in range(num_parents):\n",
    "            parents.append(self.population[indices[i]])\n",
    "        return parents\n",
    "\n",
    "    def crossover(self, parents, num_offspring):\n",
    "        offspring = []\n",
    "        for _ in range(num_offspring):\n",
    "            parent1, parent2 = np.random.choice(parents, size=2, replace=False)\n",
    "            child = FungalUnit(parent1.input_size, parent1.hidden_size, parent1.output_size)\n",
    "            for i, (p1, p2) in enumerate(zip(parent1.trainable_variables, parent2.trainable_variables)):\n",
    "                if np.random.rand() < 0.5:\n",
    "                    child.trainable_variables[i].assign(p1)\n",
    "                else:\n",
    "                    child.trainable_variables[i].assign(p2)\n",
    "            offspring.append(child)\n",
    "        return offspring\n",
    "\n",
    "    def mutation(self, offspring, mutation_rate):\n",
    "        for unit in offspring:\n",
    "            for i, variable in enumerate(unit.trainable_variables):\n",
    "                if np.random.rand() < mutation_rate:\n",
    "                    mutated = variable + np.random.normal(0.0, 0.1)\n",
    "                    unit.trainable_variables[i].assign(mutated)\n",
    "\n",
    "    def train(self, X, y, num_generations, num_parents, num_offspring, mutation_rate):\n",
    "        for generation in range(num_generations):\n",
    "            fitness_scores = self.evaluate_fitness(X, y)\n",
    "            parents = self.selection(fitness_scores, num_parents)\n",
    "            offspring = self.crossover(parents, num_offspring)\n",
    "            self.mutation(offspring, mutation_rate)\n",
    "            self.population = parents + offspring\n",
    "\n",
    "            for unit in self.population:\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    outputs = unit(X)\n",
    "                    loss = tf.losses.binary_crossentropy(y, outputs)\n",
    "                gradients = tape.gradient(loss, unit.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, unit.trainable_variables))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for unit in self.population:\n",
    "            output = unit(X)\n",
    "            predictions.append(output)\n",
    "        return np.mean(predictions, axis=0)\n",
    "\n",
    "# Hypothetical data\n",
    "X_train = np.random.rand(1000, 10)  # 1000 samples, 10 features each\n",
    "y_train = np.random.randint(2, size=1000)  # 1000 binary labels\n",
    "X_test = np.random.rand(200, 10)  # 200 samples, 10 features each\n",
    "\n",
    "# Network architecture parameters\n",
    "input_size = 10  # Number of features\n",
    "hidden_size = 20  # Size of the hidden layer\n",
    "output_size = 1  # Binary output\n",
    "population_size = 10  # Number of units in the Fungal algorithm\n",
    "\n",
    "# Evolutionary parameters\n",
    "num_generations = 10  # Number of generations\n",
    "num_parents = 4  # Number of parents selected for reproduction\n",
    "num_offspring = 6  # Number of offspring generated through crossover\n",
    "mutation_rate = 0.1  # Mutation rate\n",
    "\n",
    "# Create and train the Fungal model\n",
    "fungal = Fungal(input_size, hidden_size, output_size, population_size)\n",
    "fungal.train(X_train, y_train, num_generations, num_parents, num_offspring, mutation_rate)\n",
    "\n",
    "# Make predictions\n",
    "predictions = fungal.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
